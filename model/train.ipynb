{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20370,
     "status": "ok",
     "timestamp": 1578713695303,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "wBttfr7XvjVf",
    "outputId": "94e024a4-d4d0-4f80-8b4f-ec7940ada8c5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12601,
     "status": "ok",
     "timestamp": 1578713702373,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "nH5SjCIUv1UK",
    "outputId": "90ce897f-4ec5-4469-9d2f-628d8f2fa6ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/tobigs/poetry_generater/FINAL\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive/tobigs/poetry_generater/FINAL/\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import trange\n",
    "from model_rnn_simple import *\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "# poetry_idx\n",
    "vocab2id, id2vocab = construct_vocab(file_='/content/drive/My Drive/tobigs/poetry_generater/FINAL/data/vocab.korean_morp.list')\n",
    "image_path = \"/content/drive/My Drive/tobigs/poetry_generater/FINAL/data/kts/total/\"\n",
    "# vocab_path = 'datx`a/vocab_jamo.pkl'\n",
    "batch_size = 128\n",
    "\n",
    "# with open(vocab_path, 'rb') as f:\n",
    "#     vocab = pickle.load(f)\n",
    "\n",
    "max_poem_lens = 500\n",
    "max_keyword_counts=120\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                         (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGsZs8Slw48o"
   },
   "outputs": [],
   "source": [
    "vocab = {\"w2i\" : vocab2id, \"i2w\" : id2vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y8CYVyjwzfKC"
   },
   "outputs": [],
   "source": [
    "data_total = PoetryRNNData(image_path, transform, vocab,vocab2id, max_poem_lens, max_keyword_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 164940,
     "status": "ok",
     "timestamp": 1578713867345,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "wz0Vj1fKzfNK",
    "outputId": "af7d8993-fda0-4aaf-a837-60706728583e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 46182.91it/s]\n"
     ]
    }
   ],
   "source": [
    "all_data = data_total.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 164925,
     "status": "ok",
     "timestamp": 1578713867345,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "P8C-f2U0hkK3",
    "outputId": "3fee35ab-8da7-4b06-da05-6822e89bf7b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['beach', 'cave', 'island', 'lake', 'mountain', 'amusement park', 'palace', 'park', 'restaurant', 'tower'])"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gx5HaUBm6bSA"
   },
   "outputs": [],
   "source": [
    "train, test, val = data_total.split(all_data)\n",
    "train = [train[i]  for i in range(len(train)) if int(train[i]['keywords'][2]) != 0  ]\n",
    "test = [test[i]  for i in range(len(test)) if int(test[i]['keywords'][2]) != 0  ]\n",
    "val = [val[i]  for i in range(len(val)) if int(val[i]['keywords'][2]) != 0  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qgd35AOW8gbb"
   },
   "outputs": [],
   "source": [
    "del val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 164910,
     "status": "ok",
     "timestamp": 1578713867347,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "B_wp-LNWzfSi",
    "outputId": "2cf324a4-9b01-473d-b764-434c94d39bb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1000, 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "ok",
     "timestamp": 1578717418400,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "TkDuSjNW5AEv",
    "outputId": "591fb183-9b81-4241-9334-7330ab06d3c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dec': [[2,\n",
       "   1,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   1,\n",
       "   19,\n",
       "   3,\n",
       "   2,\n",
       "   2560,\n",
       "   1,\n",
       "   12,\n",
       "   1,\n",
       "   21,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   8,\n",
       "   2560,\n",
       "   1,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   12,\n",
       "   2320,\n",
       "   60,\n",
       "   1,\n",
       "   20,\n",
       "   90,\n",
       "   3654,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   20,\n",
       "   1,\n",
       "   12,\n",
       "   3,\n",
       "   2,\n",
       "   2116,\n",
       "   343,\n",
       "   29,\n",
       "   1,\n",
       "   1,\n",
       "   21,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   1118,\n",
       "   8,\n",
       "   1,\n",
       "   16,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   11,\n",
       "   2234,\n",
       "   9,\n",
       "   1,\n",
       "   5490,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   4712,\n",
       "   44,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   11,\n",
       "   1,\n",
       "   40,\n",
       "   8,\n",
       "   3417,\n",
       "   3,\n",
       "   2,\n",
       "   1778,\n",
       "   44,\n",
       "   1,\n",
       "   14,\n",
       "   1,\n",
       "   8,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   14,\n",
       "   1,\n",
       "   8,\n",
       "   2687,\n",
       "   3,\n",
       "   2,\n",
       "   203,\n",
       "   20,\n",
       "   450,\n",
       "   1433,\n",
       "   1,\n",
       "   14,\n",
       "   3244,\n",
       "   21,\n",
       "   3,\n",
       "   2,\n",
       "   8954,\n",
       "   20,\n",
       "   450,\n",
       "   1433,\n",
       "   1,\n",
       "   14,\n",
       "   2500,\n",
       "   5490,\n",
       "   3,\n",
       "   2,\n",
       "   859,\n",
       "   22,\n",
       "   78,\n",
       "   2113,\n",
       "   9,\n",
       "   1,\n",
       "   10,\n",
       "   1,\n",
       "   3,\n",
       "   2,\n",
       "   2113,\n",
       "   1041,\n",
       "   22,\n",
       "   1,\n",
       "   13,\n",
       "   1,\n",
       "   3,\n",
       "   4],\n",
       "  tensor(126, device='cuda:0'),\n",
       "  tensor([   2,    1,    3,    2,    1,    1,   19,    3,    2, 2560,    1,   12,\n",
       "             1,   21,    3,    2,    1,    8, 2560,    1,    3,    2,    1,   12,\n",
       "          2320,   60,    1,   20,   90, 3654,    3,    2,    1,   20,    1,   12,\n",
       "             3,    2, 2116,  343,   29,    1,    1,   21,    3,    2,    1, 1118,\n",
       "             8,    1,   16,    3,    2,    1,   11, 2234,    9,    1, 5490,    3,\n",
       "             2,    1, 4712,   44,    3,    2,    1,   11,    1,   40,    8, 3417,\n",
       "             3,    2, 1778,   44,    1,   14,    1,    8,    3,    2,    1,   14,\n",
       "             1,    8, 2687,    3,    2,  203,   20,  450, 1433,    1,   14, 3244,\n",
       "            21,    3,    2, 8954,   20,  450, 1433,    1,   14, 2500, 5490,    3,\n",
       "             2,  859,   22,   78, 2113,    9,    1,   10,    1,    3,    2, 2113,\n",
       "          1041,   22,    1,   13,    1,    3,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0], device='cuda:0'),\n",
       "  tensor([   1,    3,    2,    1,    1,   19,    3,    2, 2560,    1,   12,    1,\n",
       "            21,    3,    2,    1,    8, 2560,    1,    3,    2,    1,   12, 2320,\n",
       "            60,    1,   20,   90, 3654,    3,    2,    1,   20,    1,   12,    3,\n",
       "             2, 2116,  343,   29,    1,    1,   21,    3,    2,    1, 1118,    8,\n",
       "             1,   16,    3,    2,    1,   11, 2234,    9,    1, 5490,    3,    2,\n",
       "             1, 4712,   44,    3,    2,    1,   11,    1,   40,    8, 3417,    3,\n",
       "             2, 1778,   44,    1,   14,    1,    8,    3,    2,    1,   14,    1,\n",
       "             8, 2687,    3,    2,  203,   20,  450, 1433,    1,   14, 3244,   21,\n",
       "             3,    2, 8954,   20,  450, 1433,    1,   14, 2500, 5490,    3,    2,\n",
       "           859,   22,   78, 2113,    9,    1,   10,    1,    3,    2, 2113, 1041,\n",
       "            22,    1,   13,    1,    3,    4,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0], device='cuda:0')],\n",
       " 'img': '/content/drive/My Drive/tobigs/poetry_generater/FINAL/data/kts/total/nature-scene/beach/images/444.jpg',\n",
       " 'keywords': [[4314,\n",
       "   2218,\n",
       "   6725,\n",
       "   1,\n",
       "   1,\n",
       "   1940,\n",
       "   2113,\n",
       "   2939,\n",
       "   896,\n",
       "   1,\n",
       "   2023,\n",
       "   137,\n",
       "   8325,\n",
       "   1,\n",
       "   1778,\n",
       "   1402,\n",
       "   1,\n",
       "   718,\n",
       "   514,\n",
       "   171,\n",
       "   1,\n",
       "   1,\n",
       "   8595,\n",
       "   1,\n",
       "   1],\n",
       "  tensor([4314, 2218, 6725,    1,    1, 1940, 2113, 2939,  896,    1, 2023,  137,\n",
       "          8325,    1, 1778, 1402,    1,  718,  514,  171,    1,    1, 8595,    1,\n",
       "             1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         device='cuda:0'),\n",
       "  tensor(25)]}"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3y2qae_zjjF"
   },
   "outputs": [],
   "source": [
    "Train = PoetryRNNDataSplit(transform, vocab, train, max_poem_lens, max_keyword_counts)\n",
    "Test = PoetryRNNDataSplit(transform, vocab, test, max_poem_lens, max_keyword_counts)\n",
    "Val = PoetryRNNDataSplit(transform, vocab, val, max_poem_lens, max_keyword_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 142553,
     "status": "ok",
     "timestamp": 1578697739886,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "BBcjdlhrgWpB",
    "outputId": "74f40f61-f223-45dd-f8ba-1657d105a9c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<model_rnn_simple.PoetryRNNDataSplit at 0x7ff11e92bd30>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rqz1wVBzlFu"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(Train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHh1LX-Rv1XX"
   },
   "outputs": [],
   "source": [
    "# train, dev = train_test_split(json_data, test_size=0.001, train_size=0.99, random_state=4)\n",
    "# print(\"Length of train {} and length of dev {}\".format(len(train), len(dev)))\n",
    "\n",
    "\n",
    "prt_emb = torch.load(\"/content/drive/My Drive/tobigs/poetry_generater/FINAL/data/pytorch_model.bin\")\n",
    "weights = prt_emb['bert.embeddings.word_embeddings.weight']\n",
    "embed_weights = torch.cat([weights[:5], weights[7:]], dim=0)\n",
    "\n",
    "# embed_weights = torch.from_numpy(weights)\n",
    "# embed_weights = torch.randn(249, 512)\n",
    "\n",
    "max_topic_len = 20\n",
    "max_length = 100\n",
    "batch_size = 64\n",
    "# train_data = prepare_data_loader(train, max_topic_len, max_length, batch_size, shuffle=True)\n",
    "# dev_data = prepare_data_loader(dev, max_topic_len, max_length, batch_size=10, shuffle=False)\n",
    "\n",
    "rnn_hidden_dim = 512\n",
    "rnn_layer = 2\n",
    "rnn_bidre = False  # setting it True seems to break the data structure\n",
    "rnn_dropout = 0\n",
    "dense_dim = 300\n",
    "dense_h_dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1578715341392,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "hDFl6lBDgWpI",
    "outputId": "527b0d15-007e-482e-b732-016d4a28c33b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_weights.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0MeL0nygWpK"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2406,
     "status": "ok",
     "timestamp": 1578713949149,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "CcfpZQNDv1aM",
    "outputId": "703be8ac-b1a7-41a3-df07-42d330aee890",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "768\n",
      "Dump to cuda\n"
     ]
    }
   ],
   "source": [
    "model = PoetryRNN(encoder_embed=embed_weights, encoder_v_len=196,\n",
    "                  encoder_k_len=120,\n",
    "                  decoder_embed=embed_weights, rnn_hidden_dim=rnn_hidden_dim,\n",
    "                  rnn_layers=rnn_layer,\n",
    "                  rnn_bidre=rnn_bidre, rnn_dropout=rnn_dropout,\n",
    "                  dense_dim=dense_dim, dense_h_dropout=dense_h_dropout,\n",
    "                  freeze_embed=True)\n",
    "\n",
    "model_check_point = \"./model_results/fix_embed_model_check_point.pk\"\n",
    "if os.path.isfile(model_check_point):\n",
    "    model.load_state_dict(torch.load(model_check_point, map_location='gpu'))\n",
    "    model.train(True)\n",
    "    print(\"Load previous training parameters.\")\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    print(\"Dump to cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nkkRLIiv1c8"
   },
   "outputs": [],
   "source": [
    "model.train(True)\n",
    "import torch.nn.utils as torch_utils\n",
    "\n",
    "learning_rate = 1e-3\n",
    "loss_fn = nn.NLLLoss()\n",
    "model_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "optimizer = optim.Adam(model_params, lr=learning_rate, amsgrad=True,weight_decay=0)\n",
    "torch_utils.clip_grad_value_(model.parameters(), clip_value=0.25)\n",
    "if os.path.isfile(\"check_point_optim.pkl\"):\n",
    "    optimizer.load_state_dict(torch.load(\"check_point_optim.pkl\"))\n",
    "    print(\"Load previous optimizer.\")\n",
    "\n",
    "lr_scheme = ReduceLROnPlateau(optimizer, mode='min', factor=0.4, patience=10, min_lr=1e-7,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lyumyptwwBIl"
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torch.load('rnn_model.pk')\n",
    "model.load_state_dict(torch.load('model_check_point.pk', map_location='cpu'))\n",
    "optimizer.load_state_dict(torch.load('optimizer_check_point.pk'))\n",
    "all_loss = torch.load('all_loss_check_point.pk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xm2ng8cjugMt"
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1440164,
     "status": "error",
     "timestamp": 1578716786710,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "hJMOoHaBv1ft",
    "outputId": "c48dd64c-c030-410f-ec9a-4a78bcdea0ad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "tensor([[   1,    1,  699,  ...,    0,    0,    0],\n",
      "        [4314, 1018,    1,  ...,    0,    0,    0],\n",
      "        [   1, 3255, 2218,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4314,  699, 3255,  ...,    0,    0,    0],\n",
      "        [   1,    1, 1971,  ...,    0,    0,    0],\n",
      "        [4314,    1, 2218,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0366,  0.0283, -0.0342,  ...,  0.0522, -0.0090, -0.0372],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0319, -0.0077, -0.0433,  ..., -0.0103, -0.1079, -0.0536],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 0, loss 0.06460738182067871\n",
      "tensor([[   1, 4314,    1,  ...,    0,    0,    0],\n",
      "        [4314,    1,  699,  ...,    0,    0,    0],\n",
      "        [ 128,    1,  699,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 699,    1, 2218,  ...,    0,    0,    0],\n",
      "        [   1, 3255, 2218,  ...,    0,    0,    0],\n",
      "        [   1,    1,    0,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0175,  0.0179, -0.0018,  ...,  0.0023, -0.0545,  0.0349],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 1, loss 0.18977798521518707\n",
      "tensor([[4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [7387,    1,    1,  ...,    0,    0,    0],\n",
      "        [7387,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4314,    1, 3255,  ...,    0,    0,    0],\n",
      "        [   1, 4314,  607,  ...,    0,    0,    0],\n",
      "        [   1,    1,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0220, -0.0494, -0.0748,  ...,  0.0016, -0.1011, -0.0254],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0220, -0.0494, -0.0748,  ...,  0.0016, -0.1011, -0.0254],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0524, -0.0461, -0.0373,  ..., -0.0218, -0.0533, -0.0119],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 2, loss 0.2764715552330017\n",
      "tensor([[4314,    1,  699,  ...,    0,    0,    0],\n",
      "        [4314,  128,    1,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4314,    1,  699,  ...,    0,    0,    0],\n",
      "        [   1,    1, 3255,  ...,    0,    0,    0],\n",
      "        [   1,    1,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0175,  0.0179, -0.0018,  ...,  0.0023, -0.0545,  0.0349],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 3, loss 0.2853671610355377\n",
      "tensor([[4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1,    1,  699,  ...,    0,    0,    0],\n",
      "        [4314,    1, 3255,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4314,    1,  699,  ...,    0,    0,    0],\n",
      "        [4499, 1466, 1018,  ...,    0,    0,    0],\n",
      "        [   1,    1,    0,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0126, -0.0407, -0.0510,  ...,  0.0474, -0.0255,  0.0127],\n",
      "         [-0.0289, -0.0214, -0.0022,  ..., -0.0244, -0.0716, -0.0343],\n",
      "         [-0.0366,  0.0283, -0.0342,  ...,  0.0522, -0.0090, -0.0372],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 4, loss 0.26242175698280334\n",
      "tensor([[4314,  128,    1,  ...,    0,    0,    0],\n",
      "        [4314,  128,    1,  ...,    0,    0,    0],\n",
      "        [4314,    1,  699,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  699,    1,  ...,    0,    0,    0],\n",
      "        [4314, 3255, 2218,  ...,    0,    0,    0],\n",
      "        [   1, 3255, 2218,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0175,  0.0179, -0.0018,  ...,  0.0023, -0.0545,  0.0349],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0175,  0.0179, -0.0018,  ...,  0.0023, -0.0545,  0.0349],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 5, loss 0.2604837417602539\n",
      "tensor([[4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 607, 4314,    1,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4314,  699, 3255,  ...,    0,    0,    0],\n",
      "        [4314, 3255, 2218,  ...,    0,    0,    0],\n",
      "        [   1,    1,    0,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0524, -0.0461, -0.0373,  ..., -0.0218, -0.0533, -0.0119],\n",
      "         [-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 6, loss 0.07497423142194748\n",
      "tensor([[4314,  128,    1,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1,    1, 2218,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1, 4314,    1,  ...,    0,    0,    0],\n",
      "        [ 699, 2218, 8595,  ...,    0,    0,    0],\n",
      "        [4314,  699, 3255,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0175,  0.0179, -0.0018,  ...,  0.0023, -0.0545,  0.0349],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         [ 0.0342, -0.0779, -0.0605,  ..., -0.0493, -0.0673,  0.0049],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 7, loss 0.22181107103824615\n",
      "tensor([[   1,    1, 3887,  ...,    0,    0,    0],\n",
      "        [   1,    1,    1,  ...,    0,    0,    0],\n",
      "        [4314,    1, 2218,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1, 7387,    1,  ...,    0,    0,    0],\n",
      "        [2348, 2218,    1,  ...,    0,    0,    0],\n",
      "        [   1,    0,    0,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0048, -0.0198,  0.0549,  ..., -0.0573,  0.0080, -0.0515],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0220, -0.0494, -0.0748,  ...,  0.0016, -0.1011, -0.0254],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0232,  0.0036,  0.0084,  ..., -0.0272,  0.0348, -0.0609],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 8, loss 0.41553738713264465\n",
      "tensor([[4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1, 4314,  607,  ...,    0,    0,    0],\n",
      "        [ 699, 3103,    1,  ...,    0,    0,    0],\n",
      "        [   1,    1,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0524, -0.0461, -0.0373,  ..., -0.0218, -0.0533, -0.0119],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0654,  0.0089, -0.0411,  ...,  0.0290, -0.0271,  0.0030],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 9, loss 0.21953220665454865\n",
      "tensor([[4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1,    1, 2218,  ...,    0,    0,    0],\n",
      "        [   1,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  699, 3255,  ...,    0,    0,    0],\n",
      "        [4314,  699, 2218,  ...,    0,    0,    0],\n",
      "        [ 358, 2218,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0221, -0.0637, -0.0284,  ..., -0.0215,  0.0078, -0.0026],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 10, loss 0.27152928709983826\n",
      "tensor([[1018,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1,    1, 3255,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4314,  699, 2218,  ...,    0,    0,    0],\n",
      "        [4314,  699, 2218,  ...,    0,    0,    0],\n",
      "        [4314, 2218, 8595,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0366,  0.0283, -0.0342,  ...,  0.0522, -0.0090, -0.0372],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0155, -0.0280, -0.0115,  ..., -0.0187, -0.0167,  0.0612],\n",
      "         [ 0.0342, -0.0779, -0.0605,  ..., -0.0493, -0.0673,  0.0049],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 11, loss 0.3323858976364136\n",
      "tensor([[4314,  128,    1,  ...,    0,    0,    0],\n",
      "        [   1, 1479, 7373,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4128,  718, 6490,  ...,    0,    0,    0],\n",
      "        [ 718, 9090,    1,  ...,    0,    0,    0],\n",
      "        [4180,    1,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0175,  0.0179, -0.0018,  ...,  0.0023, -0.0545,  0.0349],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0041,  0.0160,  0.0224,  ...,  0.0443, -0.0087,  0.0021],\n",
      "         [-0.0534, -0.0293, -0.0432,  ..., -0.0292, -0.0750, -0.0348],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0300, -0.0358,  0.0016,  ..., -0.0922, -0.0500, -0.0660],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0784,  0.0154, -0.0299,  ..., -0.0720, -0.0508, -0.0109],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [ 0.0189, -0.0664, -0.0381,  ...,  0.0064, -0.0545, -0.0629],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0579, -0.0634,  0.0088,  ..., -0.0127, -0.0180, -0.0439],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 12, loss 0.6560230851173401\n",
      "tensor([[   1,  718,    1,  ...,    0,    0,    0],\n",
      "        [4180,  718,  413,  ...,    0,    0,    0],\n",
      "        [ 718,    1,  491,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,    1, 2394,  ...,    0,    0,    0],\n",
      "        [ 718,    1, 9867,  ...,    0,    0,    0],\n",
      "        [2216,  235, 2022,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0579, -0.0634,  0.0088,  ..., -0.0127, -0.0180, -0.0439],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0130,  0.0272, -0.0028,  ...,  0.0172,  0.0259, -0.0014],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0164,  0.0152, -0.0517,  ..., -0.0158, -0.0462, -0.0349],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0279, -0.0328,  0.0046,  ..., -0.0245, -0.0183, -0.0278],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0900,  0.0021, -0.1140,  ...,  0.0013,  0.0003, -0.0396],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0205,  0.0163, -0.0220,  ..., -0.0400, -0.0140, -0.0342],\n",
      "         [ 0.0085,  0.0870, -0.0347,  ..., -0.0119,  0.0026, -0.0384],\n",
      "         [ 0.0028, -0.0442, -0.0387,  ..., -0.0297, -0.0319, -0.0521],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 13, loss 0.5547351241111755\n",
      "tensor([[   1, 9090,    1,  ...,    0,    0,    0],\n",
      "        [1917,    1, 6490,  ...,    0,    0,    0],\n",
      "        [9090,  413,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [2247, 1917, 6490,  ...,    0,    0,    0],\n",
      "        [ 248,    1, 2394,  ...,    0,    0,    0],\n",
      "        [ 718, 6404,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0189, -0.0664, -0.0381,  ...,  0.0064, -0.0545, -0.0629],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0173,  0.0306,  0.0106,  ...,  0.0267, -0.0399, -0.0908],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0784,  0.0154, -0.0299,  ..., -0.0720, -0.0508, -0.0109],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0189, -0.0664, -0.0381,  ...,  0.0064, -0.0545, -0.0629],\n",
      "         [-0.0130,  0.0272, -0.0028,  ...,  0.0172,  0.0259, -0.0014],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0078, -0.0186,  0.0237,  ..., -0.0244, -0.0473, -0.0188],\n",
      "         [-0.0173,  0.0306,  0.0106,  ...,  0.0267, -0.0399, -0.0908],\n",
      "         [-0.0784,  0.0154, -0.0299,  ..., -0.0720, -0.0508, -0.0109],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0515, -0.0104, -0.0430,  ...,  0.0248,  0.0162,  0.0300],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0279, -0.0328,  0.0046,  ..., -0.0245, -0.0183, -0.0278],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [ 0.0074, -0.1382, -0.0374,  ..., -0.0061, -0.0464,  0.0186],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 14, loss 1.1136679649353027\n",
      "tensor([[   1,  718,  491,  ...,    0,    0,    0],\n",
      "        [1725,  718,  491,  ...,    0,    0,    0],\n",
      "        [1725,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4128, 1917, 9090,  ...,    0,    0,    0],\n",
      "        [4180, 8434, 1029,  ...,    0,    0,    0],\n",
      "        [ 683, 4128, 6164,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0164,  0.0152, -0.0517,  ..., -0.0158, -0.0462, -0.0349],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0097, -0.0026, -0.0284,  ...,  0.0195, -0.0232, -0.0627],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0164,  0.0152, -0.0517,  ..., -0.0158, -0.0462, -0.0349],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0097, -0.0026, -0.0284,  ...,  0.0195, -0.0232, -0.0627],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0300, -0.0358,  0.0016,  ..., -0.0922, -0.0500, -0.0660],\n",
      "         [-0.0173,  0.0306,  0.0106,  ...,  0.0267, -0.0399, -0.0908],\n",
      "         [ 0.0189, -0.0664, -0.0381,  ...,  0.0064, -0.0545, -0.0629],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0579, -0.0634,  0.0088,  ..., -0.0127, -0.0180, -0.0439],\n",
      "         [-0.0030, -0.0064, -0.0049,  ...,  0.0411, -0.0432, -0.0579],\n",
      "         [ 0.0078,  0.0521, -0.0412,  ...,  0.0115,  0.0887, -0.0599],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0486,  0.0298,  0.0629,  ..., -0.0158, -0.0479, -0.0123],\n",
      "         [ 0.0300, -0.0358,  0.0016,  ..., -0.0922, -0.0500, -0.0660],\n",
      "         [-0.0472,  0.0102,  0.0459,  ...,  0.0044, -0.0293, -0.0710],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 15, loss 1.0271282196044922\n",
      "tensor([[   1,  718,    1,  ...,    0,    0,    0],\n",
      "        [4180,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 173,  334,  366,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [6490,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 366, 1696,    1,  ...,    0,    0,    0],\n",
      "        [ 683, 2216, 1696,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0579, -0.0634,  0.0088,  ..., -0.0127, -0.0180, -0.0439],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0009, -0.0023,  0.0410,  ...,  0.0843,  0.0107, -0.0139],\n",
      "         [-0.0156, -0.0073,  0.0180,  ...,  0.0227,  0.0236, -0.0518],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0784,  0.0154, -0.0299,  ..., -0.0720, -0.0508, -0.0109],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0156, -0.0073,  0.0180,  ...,  0.0227,  0.0236, -0.0518],\n",
      "         [-0.0068, -0.0032,  0.0956,  ...,  0.0102,  0.0370, -0.0177],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0486,  0.0298,  0.0629,  ..., -0.0158, -0.0479, -0.0123],\n",
      "         [ 0.0205,  0.0163, -0.0220,  ..., -0.0400, -0.0140, -0.0342],\n",
      "         [-0.0068, -0.0032,  0.0956,  ...,  0.0102,  0.0370, -0.0177],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 16, loss 0.6940963268280029\n",
      "tensor([[ 718,    1, 6490,  ...,    0,    0,    0],\n",
      "        [   1,  718,    1,  ...,    0,    0,    0],\n",
      "        [   1,  718,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,    1, 2394,  ...,    0,    0,    0],\n",
      "        [   1, 2394,    1,  ...,    0,    0,    0],\n",
      "        [2247, 1917, 9090,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0784,  0.0154, -0.0299,  ..., -0.0720, -0.0508, -0.0109],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0279, -0.0328,  0.0046,  ..., -0.0245, -0.0183, -0.0278],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0279, -0.0328,  0.0046,  ..., -0.0245, -0.0183, -0.0278],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0078, -0.0186,  0.0237,  ..., -0.0244, -0.0473, -0.0188],\n",
      "         [-0.0173,  0.0306,  0.0106,  ...,  0.0267, -0.0399, -0.0908],\n",
      "         [ 0.0189, -0.0664, -0.0381,  ...,  0.0064, -0.0545, -0.0629],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 17, loss 0.6461811661720276\n",
      "tensor([[9090,  718, 6404,  ...,    0,    0,    0],\n",
      "        [ 366,    1,  413,  ...,    0,    0,    0],\n",
      "        [   1,  718,  491,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4128, 2247, 1917,  ...,    0,    0,    0],\n",
      "        [2216, 2022, 1402,  ...,    0,    0,    0],\n",
      "        [1223, 2939,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[ 0.0189, -0.0664, -0.0381,  ...,  0.0064, -0.0545, -0.0629],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [ 0.0074, -0.1382, -0.0374,  ..., -0.0061, -0.0464,  0.0186],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0156, -0.0073,  0.0180,  ...,  0.0227,  0.0236, -0.0518],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0130,  0.0272, -0.0028,  ...,  0.0172,  0.0259, -0.0014],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0164,  0.0152, -0.0517,  ..., -0.0158, -0.0462, -0.0349],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0300, -0.0358,  0.0016,  ..., -0.0922, -0.0500, -0.0660],\n",
      "         [-0.0078, -0.0186,  0.0237,  ..., -0.0244, -0.0473, -0.0188],\n",
      "         [-0.0173,  0.0306,  0.0106,  ...,  0.0267, -0.0399, -0.0908],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0205,  0.0163, -0.0220,  ..., -0.0400, -0.0140, -0.0342],\n",
      "         [ 0.0028, -0.0442, -0.0387,  ..., -0.0297, -0.0319, -0.0521],\n",
      "         [-0.0049, -0.0223, -0.0038,  ...,  0.0331, -0.0091,  0.0233],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0018,  0.0187,  0.0047,  ..., -0.0311,  0.0034, -0.0465],\n",
      "         [-0.0121, -0.0724, -0.0998,  ...,  0.0034,  0.0282, -0.0022],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 18, loss 0.91243577003479\n",
      "tensor([[ 366, 3887,  718,  ...,    0,    0,    0],\n",
      "        [   1, 9090,    1,  ...,    0,    0,    0],\n",
      "        [7471,    1, 1868,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 366, 1696, 2055,  ...,    0,    0,    0],\n",
      "        [4128, 1917, 6490,  ...,    0,    0,    0],\n",
      "        [1917, 6490,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0156, -0.0073,  0.0180,  ...,  0.0227,  0.0236, -0.0518],\n",
      "         [ 0.0048, -0.0198,  0.0549,  ..., -0.0573,  0.0080, -0.0515],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0189, -0.0664, -0.0381,  ...,  0.0064, -0.0545, -0.0629],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0746, -0.0410, -0.0082,  ...,  0.0250, -0.0678, -0.0361],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0679, -0.0406, -0.0216,  ..., -0.0356, -0.0698, -0.0730],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0156, -0.0073,  0.0180,  ...,  0.0227,  0.0236, -0.0518],\n",
      "         [-0.0068, -0.0032,  0.0956,  ...,  0.0102,  0.0370, -0.0177],\n",
      "         [ 0.0329,  0.0325, -0.0144,  ...,  0.0158, -0.0472,  0.0256],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0300, -0.0358,  0.0016,  ..., -0.0922, -0.0500, -0.0660],\n",
      "         [-0.0173,  0.0306,  0.0106,  ...,  0.0267, -0.0399, -0.0908],\n",
      "         [-0.0784,  0.0154, -0.0299,  ..., -0.0720, -0.0508, -0.0109],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0173,  0.0306,  0.0106,  ...,  0.0267, -0.0399, -0.0908],\n",
      "         [-0.0784,  0.0154, -0.0299,  ..., -0.0720, -0.0508, -0.0109],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 19, loss 0.7817235589027405\n",
      "tensor([[ 718,  413,    1,  ...,    0,    0,    0],\n",
      "        [4180,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 366,  718,  413,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [1479,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 366, 9090,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1, 2110,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0130,  0.0272, -0.0028,  ...,  0.0172,  0.0259, -0.0014],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0579, -0.0634,  0.0088,  ..., -0.0127, -0.0180, -0.0439],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0156, -0.0073,  0.0180,  ...,  0.0227,  0.0236, -0.0518],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0130,  0.0272, -0.0028,  ...,  0.0172,  0.0259, -0.0014],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0041,  0.0160,  0.0224,  ...,  0.0443, -0.0087,  0.0021],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0156, -0.0073,  0.0180,  ...,  0.0227,  0.0236, -0.0518],\n",
      "         [ 0.0189, -0.0664, -0.0381,  ...,  0.0064, -0.0545, -0.0629],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0125, -0.0527, -0.0436,  ..., -0.0337, -0.0017, -0.0168],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 20, loss 0.8847337365150452\n",
      "tensor([[4180,    1,  718,  ...,    0,    0,    0],\n",
      "        [ 366, 1696, 9090,  ...,    0,    0,    0],\n",
      "        [ 591,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4180, 1725, 6490,  ...,    0,    0,    0],\n",
      "        [ 366, 1696,  718,  ...,    0,    0,    0],\n",
      "        [4128, 2247, 1917,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[ 0.0579, -0.0634,  0.0088,  ..., -0.0127, -0.0180, -0.0439],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0156, -0.0073,  0.0180,  ...,  0.0227,  0.0236, -0.0518],\n",
      "         [-0.0068, -0.0032,  0.0956,  ...,  0.0102,  0.0370, -0.0177],\n",
      "         [ 0.0189, -0.0664, -0.0381,  ...,  0.0064, -0.0545, -0.0629],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0178, -0.0115,  0.0049,  ...,  0.0483, -0.0335, -0.0125],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0579, -0.0634,  0.0088,  ..., -0.0127, -0.0180, -0.0439],\n",
      "         [-0.0097, -0.0026, -0.0284,  ...,  0.0195, -0.0232, -0.0627],\n",
      "         [-0.0784,  0.0154, -0.0299,  ..., -0.0720, -0.0508, -0.0109],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0156, -0.0073,  0.0180,  ...,  0.0227,  0.0236, -0.0518],\n",
      "         [-0.0068, -0.0032,  0.0956,  ...,  0.0102,  0.0370, -0.0177],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0300, -0.0358,  0.0016,  ..., -0.0922, -0.0500, -0.0660],\n",
      "         [-0.0078, -0.0186,  0.0237,  ..., -0.0244, -0.0473, -0.0188],\n",
      "         [-0.0173,  0.0306,  0.0106,  ...,  0.0267, -0.0399, -0.0908],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 21, loss 1.0217818021774292\n",
      "tensor([[3887, 1696,  718,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 718, 6404,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 413,    1, 1664,  ...,    0,    0,    0],\n",
      "        [ 155, 1917,  718,  ...,    0,    0,    0],\n",
      "        [2216, 2022, 4731,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[ 0.0048, -0.0198,  0.0549,  ..., -0.0573,  0.0080, -0.0515],\n",
      "         [-0.0068, -0.0032,  0.0956,  ...,  0.0102,  0.0370, -0.0177],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [ 0.0074, -0.1382, -0.0374,  ..., -0.0061, -0.0464,  0.0186],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0130,  0.0272, -0.0028,  ...,  0.0172,  0.0259, -0.0014],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0534, -0.0158, -0.0313,  ..., -0.0479, -0.0295,  0.0471],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0020, -0.0225, -0.0026,  ...,  0.0326,  0.0466, -0.0276],\n",
      "         [-0.0173,  0.0306,  0.0106,  ...,  0.0267, -0.0399, -0.0908],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0205,  0.0163, -0.0220,  ..., -0.0400, -0.0140, -0.0342],\n",
      "         [ 0.0028, -0.0442, -0.0387,  ..., -0.0297, -0.0319, -0.0521],\n",
      "         [ 0.0025, -0.0210,  0.0154,  ...,  0.0161,  0.0096, -0.0589],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 22, loss 0.9832004308700562\n",
      "tensor([[ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [4180,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,    1, 2022,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [4180, 1725, 1402,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0579, -0.0634,  0.0088,  ..., -0.0127, -0.0180, -0.0439],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0028, -0.0442, -0.0387,  ..., -0.0297, -0.0319, -0.0521],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0579, -0.0634,  0.0088,  ..., -0.0127, -0.0180, -0.0439],\n",
      "         [-0.0097, -0.0026, -0.0284,  ...,  0.0195, -0.0232, -0.0627],\n",
      "         [-0.0049, -0.0223, -0.0038,  ...,  0.0331, -0.0091,  0.0233],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 23, loss 0.8954567313194275\n",
      "tensor([[11189,     1,   718,  ...,     0,     0,     0],\n",
      "        [    1,   718,  9090,  ...,     0,     0,     0],\n",
      "        [  718,     1,     1,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 4180,     1,  2110,  ...,     0,     0,     0],\n",
      "        [ 4128,  1917,  6490,  ...,     0,     0,     0],\n",
      "        [ 6490,     1,  1223,  ...,     0,     0,     0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0375, -0.0190, -0.0480,  ..., -0.0285,  0.0161, -0.0879],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [ 0.0189, -0.0664, -0.0381,  ...,  0.0064, -0.0545, -0.0629],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0579, -0.0634,  0.0088,  ..., -0.0127, -0.0180, -0.0439],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0125, -0.0527, -0.0436,  ..., -0.0337, -0.0017, -0.0168],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0300, -0.0358,  0.0016,  ..., -0.0922, -0.0500, -0.0660],\n",
      "         [-0.0173,  0.0306,  0.0106,  ...,  0.0267, -0.0399, -0.0908],\n",
      "         [-0.0784,  0.0154, -0.0299,  ..., -0.0720, -0.0508, -0.0109],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0784,  0.0154, -0.0299,  ..., -0.0720, -0.0508, -0.0109],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0018,  0.0187,  0.0047,  ..., -0.0311,  0.0034, -0.0465],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 24, loss 0.6854881048202515\n",
      "tensor([[ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1,  718,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 718,    1, 2113,  ...,    0,    0,    0],\n",
      "        [ 718,    1, 8325,  ...,    0,    0,    0],\n",
      "        [3255,  718,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0518, -0.0511, -0.0248,  ..., -0.0897, -0.0285,  0.0151],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0219, -0.0554, -0.0513,  ..., -0.0603, -0.0834, -0.0263],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 25, loss 0.1481725126504898\n",
      "tensor([[ 173,    1,  718,  ...,    0,    0,    0],\n",
      "        [ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 173, 9167,  718,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0633, -0.0085, -0.0723,  ..., -0.0039, -0.0674, -0.0414],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 26, loss 0.25544312596321106\n",
      "tensor([[ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [3255,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 173, 3255,  718,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [3255,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1, 2113,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0518, -0.0511, -0.0248,  ..., -0.0897, -0.0285,  0.0151],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 27, loss 0.09306616336107254\n",
      "tensor([[ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 173,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [3255,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 28, loss 0.15456083416938782\n",
      "tensor([[3255,  718,    1,  ...,    0,    0,    0],\n",
      "        [3255,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [3255,  718,    1,  ...,    0,    0,    0],\n",
      "        [3255,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 29, loss 0.21417956054210663\n",
      "tensor([[   1,  718,    1,  ...,    0,    0,    0],\n",
      "        [   1,  718, 3255,  ...,    0,    0,    0],\n",
      "        [   1,  718,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [7471,  718,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0746, -0.0410, -0.0082,  ...,  0.0250, -0.0678, -0.0361],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 30, loss 0.09086456894874573\n",
      "tensor([[ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1, 2113,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0518, -0.0511, -0.0248,  ..., -0.0897, -0.0285,  0.0151],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 31, loss 0.23656579852104187\n",
      "tensor([[ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [7585,  718,    1,  ...,    0,    0,    0],\n",
      "        [   1, 3255,  718,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-6.2512e-02, -5.5405e-03,  1.1787e-02,  ...,  2.5068e-02,\n",
      "          -7.9491e-02, -5.3165e-02],\n",
      "         [-4.6956e-02,  2.1650e-02, -1.5383e-02,  ..., -3.9082e-02,\n",
      "           2.5253e-02,  2.1470e-02],\n",
      "         [-4.6956e-02,  2.1650e-02, -1.5383e-02,  ..., -3.9082e-02,\n",
      "           2.5253e-02,  2.1470e-02],\n",
      "         ...,\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03],\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03],\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03]],\n",
      "\n",
      "        [[-2.6868e-02, -4.5631e-05,  2.4150e-02,  ..., -4.9560e-03,\n",
      "          -1.0392e-01,  2.7928e-02],\n",
      "         [-6.2512e-02, -5.5405e-03,  1.1787e-02,  ...,  2.5068e-02,\n",
      "          -7.9491e-02, -5.3165e-02],\n",
      "         [-4.6956e-02,  2.1650e-02, -1.5383e-02,  ..., -3.9082e-02,\n",
      "           2.5253e-02,  2.1470e-02],\n",
      "         ...,\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03],\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03],\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03]],\n",
      "\n",
      "        [[-4.6956e-02,  2.1650e-02, -1.5383e-02,  ..., -3.9082e-02,\n",
      "           2.5253e-02,  2.1470e-02],\n",
      "         [-4.0758e-02, -4.4723e-02, -3.2689e-02,  ...,  1.5943e-02,\n",
      "           5.6560e-03, -2.3574e-02],\n",
      "         [-6.2512e-02, -5.5405e-03,  1.1787e-02,  ...,  2.5068e-02,\n",
      "          -7.9491e-02, -5.3165e-02],\n",
      "         ...,\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03],\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03],\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.2512e-02, -5.5405e-03,  1.1787e-02,  ...,  2.5068e-02,\n",
      "          -7.9491e-02, -5.3165e-02],\n",
      "         [-4.6956e-02,  2.1650e-02, -1.5383e-02,  ..., -3.9082e-02,\n",
      "           2.5253e-02,  2.1470e-02],\n",
      "         [-4.6956e-02,  2.1650e-02, -1.5383e-02,  ..., -3.9082e-02,\n",
      "           2.5253e-02,  2.1470e-02],\n",
      "         ...,\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03],\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03],\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03]],\n",
      "\n",
      "        [[-6.2512e-02, -5.5405e-03,  1.1787e-02,  ...,  2.5068e-02,\n",
      "          -7.9491e-02, -5.3165e-02],\n",
      "         [-4.6956e-02,  2.1650e-02, -1.5383e-02,  ..., -3.9082e-02,\n",
      "           2.5253e-02,  2.1470e-02],\n",
      "         [-4.6956e-02,  2.1650e-02, -1.5383e-02,  ..., -3.9082e-02,\n",
      "           2.5253e-02,  2.1470e-02],\n",
      "         ...,\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03],\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03],\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03]],\n",
      "\n",
      "        [[-6.2512e-02, -5.5405e-03,  1.1787e-02,  ...,  2.5068e-02,\n",
      "          -7.9491e-02, -5.3165e-02],\n",
      "         [-4.6956e-02,  2.1650e-02, -1.5383e-02,  ..., -3.9082e-02,\n",
      "           2.5253e-02,  2.1470e-02],\n",
      "         [-4.6956e-02,  2.1650e-02, -1.5383e-02,  ..., -3.9082e-02,\n",
      "           2.5253e-02,  2.1470e-02],\n",
      "         ...,\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03],\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03],\n",
      "         [-2.7620e-02,  1.0176e-02, -2.7569e-02,  ...,  2.8714e-03,\n",
      "          -9.3293e-03, -4.1853e-03]]], device='cuda:0')\n",
      "Current batch 32, loss 0.17893798649311066\n",
      "tensor([[ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        [   1,  718,  491,  ...,    0,    0,    0],\n",
      "        [ 173, 1778,  718,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [3255,  718,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0164,  0.0152, -0.0517,  ..., -0.0158, -0.0462, -0.0349],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0180, -0.0796, -0.0315,  ..., -0.0308, -0.0446, -0.0399],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 33, loss 0.17550258338451385\n",
      "tensor([[ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [3255,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 718,  491,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0164,  0.0152, -0.0517,  ..., -0.0158, -0.0462, -0.0349],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 34, loss 0.18794502317905426\n",
      "tensor([[ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [3255,  718,    1,  ...,    0,    0,    0],\n",
      "        [3255,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1, 2113,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0518, -0.0511, -0.0248,  ..., -0.0897, -0.0285,  0.0151],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 35, loss 0.19499801099300385\n",
      "tensor([[ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 173,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1, 2113,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0749, -0.0932,  0.0118,  ..., -0.0126, -0.0243,  0.0301],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0518, -0.0511, -0.0248,  ..., -0.0897, -0.0285,  0.0151],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 36, loss 0.3688798248767853\n",
      "tensor([[1778,    1,  718,  ...,    0,    0,    0],\n",
      "        [   1,    1,  137,  ...,    0,    0,    0],\n",
      "        [   1,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  137, 1778,  ...,    0,    0,    0],\n",
      "        [1778,  718,    1,  ...,    0,    0,    0],\n",
      "        [ 718,    1,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0180, -0.0796, -0.0315,  ..., -0.0308, -0.0446, -0.0399],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0183,  0.0131, -0.0328,  ...,  0.0437,  0.0653,  0.0050],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0183,  0.0131, -0.0328,  ...,  0.0437,  0.0653,  0.0050],\n",
      "         [-0.0180, -0.0796, -0.0315,  ..., -0.0308, -0.0446, -0.0399],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0180, -0.0796, -0.0315,  ..., -0.0308, -0.0446, -0.0399],\n",
      "         [-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0625, -0.0055,  0.0118,  ...,  0.0251, -0.0795, -0.0532],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 37, loss 0.27583047747612\n",
      "tensor([[   1,  137,    1,  ...,    0,    0,    0],\n",
      "        [   1,  137,    1,  ...,    0,    0,    0],\n",
      "        [   1,  171,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  137, 1778,  ...,    0,    0,    0],\n",
      "        [   1,  137,    1,  ...,    0,    0,    0],\n",
      "        [   1,    1,  137,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0183,  0.0131, -0.0328,  ...,  0.0437,  0.0653,  0.0050],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0183,  0.0131, -0.0328,  ...,  0.0437,  0.0653,  0.0050],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0041,  0.0535,  0.0534,  ..., -0.0380,  0.0201, -0.0250],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0183,  0.0131, -0.0328,  ...,  0.0437,  0.0653,  0.0050],\n",
      "         [-0.0180, -0.0796, -0.0315,  ..., -0.0308, -0.0446, -0.0399],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0183,  0.0131, -0.0328,  ...,  0.0437,  0.0653,  0.0050],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0183,  0.0131, -0.0328,  ...,  0.0437,  0.0653,  0.0050],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 38, loss 0.3309907913208008\n",
      "tensor([[4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [4314,  171,  137,  ...,    0,    0,    0],\n",
      "        [   1,  137, 8603,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 137,    1, 1778,  ...,    0,    0,    0],\n",
      "        [ 171,  137, 1778,  ...,    0,    0,    0],\n",
      "        [ 137,    1, 1778,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([64, 512, 14, 14])\n",
      "torch.Size([64, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0041,  0.0535,  0.0534,  ..., -0.0380,  0.0201, -0.0250],\n",
      "         [ 0.0183,  0.0131, -0.0328,  ...,  0.0437,  0.0653,  0.0050],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0183,  0.0131, -0.0328,  ...,  0.0437,  0.0653,  0.0050],\n",
      "         [-0.0706,  0.0023,  0.0003,  ..., -0.0546, -0.0763,  0.0200],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0183,  0.0131, -0.0328,  ...,  0.0437,  0.0653,  0.0050],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0180, -0.0796, -0.0315,  ..., -0.0308, -0.0446, -0.0399],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0041,  0.0535,  0.0534,  ..., -0.0380,  0.0201, -0.0250],\n",
      "         [ 0.0183,  0.0131, -0.0328,  ...,  0.0437,  0.0653,  0.0050],\n",
      "         [-0.0180, -0.0796, -0.0315,  ..., -0.0308, -0.0446, -0.0399],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[ 0.0183,  0.0131, -0.0328,  ...,  0.0437,  0.0653,  0.0050],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0180, -0.0796, -0.0315,  ..., -0.0308, -0.0446, -0.0399],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "Current batch 39, loss 0.257625013589859\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2513d8c98f2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"starting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/My Drive/tobigs/poetry_generater/FINAL/model_rnn_simple.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# imgaes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_path_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2773\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2775\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2777\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "# all_loss = []\n",
    "t_range = trange(10)\n",
    "for iteration in t_range:\n",
    "    print(\"starting...\")\n",
    "    losses = []\n",
    "    for batch in train_loader:\n",
    "        out = sort_batches(batch)\n",
    "        model.zero_grad()\n",
    "        #print(out['x'])\n",
    "        #print(out['keyword'])\n",
    "        target_score, hidden = model(out['img'],\n",
    "                                    # \n",
    "                                     out['keyword'][0], out['keyword'][1], out['keyword'][2],\n",
    "                                    #  out['x_pre'][0], out['x_pre'][1], out['x_pre'][2],\n",
    "                                     out['x'][0], out['x'][1], out['x'][2])        # batch*seq_len x vocab dim\n",
    "        loss = loss_fn(target_score, out['y'])\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "        optimizer.step()\n",
    "        # lr_scheme.step(loss.data[0])\n",
    "        print(\"Current batch {}, loss {}\".format(counter, loss.item()))\n",
    "        losses.append(loss.item())\n",
    "        counter += 1\n",
    "        all_loss.append(loss.item())\n",
    "\n",
    "    one_ite_loss = np.mean(losses)\n",
    "    lr_scheme.step(one_ite_loss)\n",
    "    print(\"One iteration loss {:.3f}\".format(one_ite_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 801
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1644761,
     "status": "ok",
     "timestamp": 1578705680195,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "SWoK-TTkv1iY",
    "outputId": "6a0bece4-36e6-4930-dc57-9070857ee084"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type PoetryRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type VisualEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm1d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type PoetryEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type VisualAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Softmax. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SELU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type KeywordAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type PoetryDecoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model_check_point.pk')\n",
    "torch.save(model, 'rnn_model.pk')\n",
    "torch.save(optimizer.state_dict(), 'optimizer_check_point.pk')\n",
    "torch.save(all_loss, 'all_loss_check_point.pk')\n",
    "\n",
    "import torch\n",
    "a = torch.randn(10,5,2)\n",
    "lengths = [5,4,3,2,1,1,2,3,4,5]\n",
    "for i in range(len(lengths)):\n",
    "    if lengths[i] < a[i,:].size(0):\n",
    "        a[i, lengths[i]:, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1636,
     "status": "ok",
     "timestamp": 1578714174024,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "Vykp0Hamr62q",
    "outputId": "3acd55ad-4fed-4a0c-85f5-5a5bbd7fd3ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fQlRGLHsrRi"
   },
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKFzi0V1r2kX"
   },
   "outputs": [],
   "source": [
    "# optimizer.load_state_dict(torch.load('optimizer_check_point.pk'))\n",
    "# model.load_state_dict(torch.load('all_loss_check_point.pk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnWXqI1Mv1lJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NRoCL2W2Nlan"
   },
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1078,
     "status": "ok",
     "timestamp": 1578716851100,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "FPDG0UkufyE6",
    "outputId": "d1f38e45-c18d-43e2-f686-93bba3a7f18b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoetryRNN(\n",
       "  (encoder_v): VisualEncoder(\n",
       "    (vgg19): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): ReLU(inplace=True)\n",
       "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): ReLU(inplace=True)\n",
       "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (33): ReLU(inplace=True)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (linear): Linear(in_features=196, out_features=768, bias=True)\n",
       "    (bn): BatchNorm1d(768, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (encoder_k): PoetryEncoder(\n",
       "    (embed): Embedding(30347, 768)\n",
       "    (rnn): GRU(768, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (attention_v): VisualAttention(\n",
       "    (atten_weights): Linear(in_features=512, out_features=768, bias=True)\n",
       "    (softmax): Softmax(dim=2)\n",
       "    (context_out): Linear(in_features=964, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation_out): SELU()\n",
       "  )\n",
       "  (attention_k): KeywordAttention(\n",
       "    (atten_weights): Linear(in_features=512, out_features=768, bias=True)\n",
       "    (softmax): Softmax(dim=2)\n",
       "    (context_out): Linear(in_features=888, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation_out): SELU()\n",
       "  )\n",
       "  (decoder): PoetryDecoder(\n",
       "    (embed): Embedding(30347, 768)\n",
       "    (tanh): Tanh()\n",
       "    (rnn): LSTM(768, 512, num_layers=2, batch_first=True)\n",
       "    (dense_h0): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=300, bias=True)\n",
       "      (1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): SELU()\n",
       "      (Dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (dense_h1): Sequential(\n",
       "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): SELU()\n",
       "      (Dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (dense_h2): Sequential(\n",
       "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): SELU()\n",
       "      (Dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (dense_h3): Sequential(\n",
       "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): SELU()\n",
       "      (Dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (output_linear): Linear(in_features=300, out_features=30347, bias=True)\n",
       "    (log_softmax): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zyen9J2o3pgB"
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(Test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2472,
     "status": "error",
     "timestamp": 1578718421403,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "8vmQGK1lNqa1",
    "outputId": "2511ffb3-d425-444f-c5b7-3f8164fdad85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4314,    1,  699,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1, 3887,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4314,    1, 3255,  ...,    0,    0,    0],\n",
      "        [4314, 1530, 3255,  ...,    0,    0,    0],\n",
      "        [4314,  699, 3255,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([10, 512, 14, 14])\n",
      "torch.Size([10, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0048, -0.0198,  0.0549,  ..., -0.0573,  0.0080, -0.0515],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0060, -0.0601, -0.0076,  ...,  0.0119, -0.0171,  0.0234],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "tensor([[4314,    1,  699,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1, 3887,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4314,    1, 3255,  ...,    0,    0,    0],\n",
      "        [4314, 1530, 3255,  ...,    0,    0,    0],\n",
      "        [4314,  699, 3255,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([10, 512, 14, 14])\n",
      "torch.Size([10, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0048, -0.0198,  0.0549,  ..., -0.0573,  0.0080, -0.0515],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0060, -0.0601, -0.0076,  ...,  0.0119, -0.0171,  0.0234],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "tensor([[4314,    1,  699,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1, 3887,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4314,    1, 3255,  ...,    0,    0,    0],\n",
      "        [4314, 1530, 3255,  ...,    0,    0,    0],\n",
      "        [4314,  699, 3255,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([10, 512, 14, 14])\n",
      "torch.Size([10, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0048, -0.0198,  0.0549,  ..., -0.0573,  0.0080, -0.0515],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0060, -0.0601, -0.0076,  ...,  0.0119, -0.0171,  0.0234],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "tensor([[4314,    1,  699,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1, 3887,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4314,    1, 3255,  ...,    0,    0,    0],\n",
      "        [4314, 1530, 3255,  ...,    0,    0,    0],\n",
      "        [4314,  699, 3255,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([10, 512, 14, 14])\n",
      "torch.Size([10, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0048, -0.0198,  0.0549,  ..., -0.0573,  0.0080, -0.0515],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0060, -0.0601, -0.0076,  ...,  0.0119, -0.0171,  0.0234],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "tensor([[4314,    1,  699,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1, 3887,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4314,    1, 3255,  ...,    0,    0,    0],\n",
      "        [4314, 1530, 3255,  ...,    0,    0,    0],\n",
      "        [4314,  699, 3255,  ...,    0,    0,    0]], device='cuda:0')\n",
      "before torch.Size([10, 512, 14, 14])\n",
      "torch.Size([10, 196, 512])\n",
      "tensor([[[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [ 0.0048, -0.0198,  0.0549,  ..., -0.0573,  0.0080, -0.0515],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0060, -0.0601, -0.0076,  ...,  0.0119, -0.0171,  0.0234],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]],\n",
      "\n",
      "        [[-0.0825, -0.0106, -0.0255,  ...,  0.0079, -0.0494, -0.0242],\n",
      "         [ 0.0299,  0.1107, -0.0565,  ...,  0.0058,  0.0384, -0.0482],\n",
      "         [-0.0408, -0.0447, -0.0327,  ...,  0.0159,  0.0057, -0.0236],\n",
      "         ...,\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
      "         [-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042]]],\n",
      "       device='cuda:0')\n",
      "tensor([[4314,    1,  699,  ...,    0,    0,    0],\n",
      "        [4314,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1, 3887,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4314,    1, 3255,  ...,    0,    0,    0],\n",
      "        [4314, 1530, 3255,  ...,    0,    0,    0],\n",
      "        [4314,  699, 3255,  ...,    0,    0,    0]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-b9bc95e33b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   target_score, hidden_state = model.predict(out['img'],\n\u001b[1;32m      6\u001b[0m                                      \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keyword'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keyword'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keyword'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                      out['x'][0], out['x'][1], out['x'][2])\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/My Drive/tobigs/poetry_generater/FINAL/model_rnn_simple.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, batch_img, batch_k, k_lens, k_lens_sort, batch_input, sorted_lens, inverted_ks_idx)\u001b[0m\n\u001b[1;32m    769\u001b[0m                                         \u001b[0mbatch_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_lens_sort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m                                         \u001b[0;31m# batch_pre, pre_lens, pre_lens_sort,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                                         batch_input, sorted_lens, inverted_ks_idx)\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/My Drive/tobigs/poetry_generater/FINAL/model_rnn_simple.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_img, batch_k, k_lens, k_lens_sort, batch_input, sorted_lens, inverted_ks_idx)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;31m# 바뀐 순서를 여기서 처리???\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         \u001b[0mencoded_output_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m         \u001b[0;31m# encoded_output, encoded_hidden = self.encoder.forward(batch_pre, pre_lens)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;31m# encoded_output = encoded_output.index_select(dim=0, index=sorted_idx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/My Drive/tobigs/poetry_generater/FINAL/model_rnn_simple.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;34m\"\"\"Extract feature vectors from input images.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"before\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 124.00 MiB (GPU 0; 15.90 GiB total capacity; 15.06 GiB already allocated; 15.88 MiB free; 126.95 MiB cached)"
     ]
    }
   ],
   "source": [
    "target = []\n",
    "for i in range(20):\n",
    "  batch = next(iter(test_loader))\n",
    "  out = sort_batches(batch)\n",
    "  target_score, hidden_state = model.predict(out['img'],\n",
    "                                     out['keyword'][0], out['keyword'][1], out['keyword'][2],\n",
    "                                     out['x'][0], out['x'][1], out['x'][2])\n",
    "  model.zero_grad()\n",
    "  target.append(target_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1578718431851,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "rbGr29-9vVB3",
    "outputId": "6189523a-8641-47f1-c3c9-3c7a36f5d683"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1174,
     "status": "error",
     "timestamp": 1578718446077,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "4NwHrv3ftu8H",
    "outputId": "edf015ca-3f10-4a1a-b93b-224eb5f586a2"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-d00531f31c73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 168.00 MiB (GPU 0; 15.90 GiB total capacity; 15.06 GiB already allocated; 15.88 MiB free; 126.95 MiB cached)"
     ]
    }
   ],
   "source": [
    "target_score = F.softmax(target[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1548,
     "status": "ok",
     "timestamp": 1578716926669,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "hlwSVjfrt21D",
    "outputId": "950dadc5-cef7-4283-c5bf-fca9e0d4fa37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1434, 30347])"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lyUTt94ujZ6"
   },
   "outputs": [],
   "source": [
    "pred = [ int(torch.argmax(target_score[i])) for i in range(len(target_score))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPPFFfzjvBES"
   },
   "outputs": [],
   "source": [
    "id2vocab[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLWys7aDu99h"
   },
   "outputs": [],
   "source": [
    "poem_list = [ id2vocab[i] for i in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w87XnJpbOdpm"
   },
   "outputs": [],
   "source": [
    "poem_list = ' '.join(poem_list).split('[STOP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1225,
     "status": "ok",
     "timestamp": 1578717832083,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "5zEmUtLg6k6s",
    "outputId": "a71d99c5-afc6-4469-d7af-f2c78d275ee4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [UNK] [SEP] [CLS] [UNK] [UNK] 부터/JX_ [UNK] ㄴ/ETM_ 마음/NNG_ 에/JKB_ [SEP] [CLS] 가슴/NNG_ 설레/VV_ 며/EC_ 짐/NNG_ [UNK] [UNK] 챙기/VV_ 고서/EC_ [SEP] [CLS] [UNK] 하/XSA_ ㄴ/ETM_ 도시/NNG_ 와/JC_ 바쁘/VA_ ㄴ/ETM_ 일상/NNG_ 을/JKO_ 벗어나/VV_ 아/EC_ [SEP] [CLS] [UNK] [UNK] 유/NNG_ 롭/XSA_ 게/EC_ 휴가/NNG_ 떠나/VV_ 는/ETM_ 시기/NNG_ [SEP] [CLS] 즐겁/VA_ ㄴ/ETM_ 휴식/NNG_ [UNK] 하/XSV_ 여/EC_ 보/VX_ 는/ETM_ 여름/NNG_ [UNK] [SEP] [CLS] 맑/VA_ 은/ETM_ 물/NNG_ 이/JKS_ 소리/NNG_ 내/VV_ 며/EC_ [UNK] 는/ETM_ 계곡/NNG_ [SEP] [CLS] [UNK] 하/XSA_ ㄴ/ETM_ 바람/NNG_ 불/VV_ 어/EC_ 오/VV_ 는/ETM_ 숲/NNG_ 속/NNG_ [UNK] 이/MAG_ 든/EC_ [SEP] [CLS] 이르/VA_ ㄴ/ETM_ 아침/NNG_ [UNK] 끼/VV_ ㄴ/ETM_ [UNK] 의/JKG_ 풍경/NNG_ 들/XSN_ 이/JKS_ [SEP] [CLS] 한/MM_ 폭/NNG_ 의/JKG_ 그림/NNG_ 처럼/JKB_ [UNK] 는/ETM_ 오토/NNG_ [UNK] [SEP] [CLS] [UNK] ㄴ/ETM_ 바다/NNG_ 하얗/VA_ ㄴ/ETM_ [UNK] 펼쳐지/VV_ ㄴ/ETM_ [UNK] [SEP] [CLS] 가/VV_ 아/EC_ 보/VX_ ㄹ/ETM_ 만/NNB_ 하/XSA_ ㄴ/ETM_ 곳/NNG_ 으로/JKB_ 잘/MAG_ 알리/VV_ 어/EC_ 지/VX_ ㄴ/ETM_ [UNK] [UNK] 찾/VV_ 아/EC_ [SEP] [CLS] [UNK] ㄴ/ETM_ 사람/NNG_ 끼리/XSN_ 이/VCP_ 라면/EC_ 장소/NNG_ 야/JX_ 어디/NP_ 이/VCP_ 든/EC_ 상/MAG_ 관/NNG_ 없이/MAG_ [SEP] [CLS] [UNK] 찾/VV_ 아/EC_ 길/NNG_ 떠나/VV_ 는/ETM_ 것/NNB_ 만/JX_ 으로/JKB_ 도/JX_ 너무/MAG_ 행복/NNG_ 하/XSA_ ㄴ/ETM_ [SEP] [CLS] [UNK] 뜻/NNG_ 깊/VA_ 은/ETM_ 추억/NNG_ 만들/VV_ 어/EC_ 보/VX_ 는/ETM_ [UNK] 여름/NNG_ 의/JKG_ 절정/NNG_ [SEP] '"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1578717849549,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "VBzKca9o6pOr",
    "outputId": "dae5b055-1092-4525-c1c4-e39eb1779fc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dec': [[2,\n",
       "   1,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   1,\n",
       "   19,\n",
       "   3,\n",
       "   2,\n",
       "   2560,\n",
       "   1,\n",
       "   12,\n",
       "   1,\n",
       "   21,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   8,\n",
       "   2560,\n",
       "   1,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   12,\n",
       "   2320,\n",
       "   60,\n",
       "   1,\n",
       "   20,\n",
       "   90,\n",
       "   3654,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   20,\n",
       "   1,\n",
       "   12,\n",
       "   3,\n",
       "   2,\n",
       "   2116,\n",
       "   343,\n",
       "   29,\n",
       "   1,\n",
       "   1,\n",
       "   21,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   1118,\n",
       "   8,\n",
       "   1,\n",
       "   16,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   11,\n",
       "   2234,\n",
       "   9,\n",
       "   1,\n",
       "   5490,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   4712,\n",
       "   44,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   11,\n",
       "   1,\n",
       "   40,\n",
       "   8,\n",
       "   3417,\n",
       "   3,\n",
       "   2,\n",
       "   1778,\n",
       "   44,\n",
       "   1,\n",
       "   14,\n",
       "   1,\n",
       "   8,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   14,\n",
       "   1,\n",
       "   8,\n",
       "   2687,\n",
       "   3,\n",
       "   2,\n",
       "   203,\n",
       "   20,\n",
       "   450,\n",
       "   1433,\n",
       "   1,\n",
       "   14,\n",
       "   3244,\n",
       "   21,\n",
       "   3,\n",
       "   2,\n",
       "   8954,\n",
       "   20,\n",
       "   450,\n",
       "   1433,\n",
       "   1,\n",
       "   14,\n",
       "   2500,\n",
       "   5490,\n",
       "   3,\n",
       "   2,\n",
       "   859,\n",
       "   22,\n",
       "   78,\n",
       "   2113,\n",
       "   9,\n",
       "   1,\n",
       "   10,\n",
       "   1,\n",
       "   3,\n",
       "   2,\n",
       "   2113,\n",
       "   1041,\n",
       "   22,\n",
       "   1,\n",
       "   13,\n",
       "   1,\n",
       "   3,\n",
       "   4],\n",
       "  tensor(126, device='cuda:0'),\n",
       "  tensor([   2,    1,    3,    2,    1,    1,   19,    3,    2, 2560,    1,   12,\n",
       "             1,   21,    3,    2,    1,    8, 2560,    1,    3,    2,    1,   12,\n",
       "          2320,   60,    1,   20,   90, 3654,    3,    2,    1,   20,    1,   12,\n",
       "             3,    2, 2116,  343,   29,    1,    1,   21,    3,    2,    1, 1118,\n",
       "             8,    1,   16,    3,    2,    1,   11, 2234,    9,    1, 5490,    3,\n",
       "             2,    1, 4712,   44,    3,    2,    1,   11,    1,   40,    8, 3417,\n",
       "             3,    2, 1778,   44,    1,   14,    1,    8,    3,    2,    1,   14,\n",
       "             1,    8, 2687,    3,    2,  203,   20,  450, 1433,    1,   14, 3244,\n",
       "            21,    3,    2, 8954,   20,  450, 1433,    1,   14, 2500, 5490,    3,\n",
       "             2,  859,   22,   78, 2113,    9,    1,   10,    1,    3,    2, 2113,\n",
       "          1041,   22,    1,   13,    1,    3,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0], device='cuda:0'),\n",
       "  tensor([   1,    3,    2,    1,    1,   19,    3,    2, 2560,    1,   12,    1,\n",
       "            21,    3,    2,    1,    8, 2560,    1,    3,    2,    1,   12, 2320,\n",
       "            60,    1,   20,   90, 3654,    3,    2,    1,   20,    1,   12,    3,\n",
       "             2, 2116,  343,   29,    1,    1,   21,    3,    2,    1, 1118,    8,\n",
       "             1,   16,    3,    2,    1,   11, 2234,    9,    1, 5490,    3,    2,\n",
       "             1, 4712,   44,    3,    2,    1,   11,    1,   40,    8, 3417,    3,\n",
       "             2, 1778,   44,    1,   14,    1,    8,    3,    2,    1,   14,    1,\n",
       "             8, 2687,    3,    2,  203,   20,  450, 1433,    1,   14, 3244,   21,\n",
       "             3,    2, 8954,   20,  450, 1433,    1,   14, 2500, 5490,    3,    2,\n",
       "           859,   22,   78, 2113,    9,    1,   10,    1,    3,    2, 2113, 1041,\n",
       "            22,    1,   13,    1,    3,    4,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0], device='cuda:0')],\n",
       " 'img': '/content/drive/My Drive/tobigs/poetry_generater/FINAL/data/kts/total/nature-scene/beach/images/539.jpg',\n",
       " 'keywords': [[4314,\n",
       "   699,\n",
       "   3255,\n",
       "   2218,\n",
       "   1,\n",
       "   1,\n",
       "   2023,\n",
       "   137,\n",
       "   8325,\n",
       "   1,\n",
       "   1778,\n",
       "   1,\n",
       "   1402,\n",
       "   718,\n",
       "   514,\n",
       "   171,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   8595,\n",
       "   1,\n",
       "   1],\n",
       "  tensor([4314,  699, 3255, 2218,    1,    1, 2023,  137, 8325,    1, 1778,    1,\n",
       "          1402,  718,  514,  171,    1,    1,    1, 8595,    1,    1,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         device='cuda:0'),\n",
       "  tensor(22)]}"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1211,
     "status": "ok",
     "timestamp": 1578717711462,
     "user": {
      "displayName": "김태욱",
      "photoUrl": "",
      "userId": "14910750490911394154"
     },
     "user_tz": -540
    },
    "id": "uBNJwzgTkCux",
    "outputId": "db4a1f10-416c-4f2d-cbf9-e2fdd53f7db9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK] 가/VV_ 다가/EC_ [UNK] [UNK] 로/JKB_ 빠지/VV_ ㄴ다는/ETM_ 말/NNG_ 이/JKS_ ',\n",
       " ' [CLS] [UNK] 이/JKC_ 아니/VCN_ 라는/ETM_ 것/NNB_ ㄹ/JKO_ ',\n",
       " ' [CLS] [UNK] 포/NNG_ 의/JKG_ 매력/NNG_ 에/JKB_ 빠지/VV_ 어/EC_ 보/VX_ ㄴ/ETM_ 사람/NNG_ 은/JX_ 알/VV_ ㄴ다/EC_ ',\n",
       " ' [CLS] [UNK] 포/NNG_ 가/JKS_ 얼마나/MAG_ [UNK] ㄴ/ETM_ 곳/NNG_ 이/VCP_ ㄴ가/EC_ 를/JKO_ ',\n",
       " ' [CLS] [UNK] [UNK] 교/NNG_ 의/JKG_ [UNK] ㄴ/ETM_ 풍경/NNG_ 이야/JX_ 말/NNG_ 하/XSV_ ㄹ/ETM_ 것/NNB_ 도/JX_ 없/VA_ 고/EC_ ',\n",
       " ' [CLS] 호수/NNG_ 같/VA_ 은/ETM_ 바다/NNG_ 의/JKG_ 풍경/NNG_ 이야/JX_ 너무/MAG_ 도/JX_ [UNK] 하/XSA_ 고/EC_ ',\n",
       " ' [CLS] [UNK] 에/JKB_ 담/VV_ 은/ETM_ 바다/NNG_ 의/JKG_ [UNK] 맛/NNG_ 또한/MAG_ 천하/NNG_ 의/JKG_ [UNK] 이/VCP_ 지/EC_ ',\n",
       " ' [CLS] [UNK] 섬/NNG_ 의/JKG_ 매력/NNG_ 은/JX_ 더/MAG_ 하/XSV_ ㄹ/ETM_ [UNK] 도/JX_ 없/VA_ 고/EC_ ',\n",
       " ' [CLS] 여러/MM_ 섬/NNG_ 을/JKO_ 오가/VV_ 는/ETM_ 항구/NNG_ 의/JKG_ 배/NNG_ 들/XSN_ 이야/JX_ ',\n",
       " ' [CLS] 꿈/NNG_ 과/JC_ 행복/NNG_ 을/JKO_ 나르/VV_ 느라/EC_ [UNK] 이/JKS_ 없/VA_ 지/EC_ ',\n",
       " ' [CLS] 바다/NNG_ 에/JKB_ 는/JX_ [UNK] 이/JKS_ 검/VA_ 어/EC_ 지/VX_ 고/EC_ ',\n",
       " ' [CLS] [UNK] 들/XSN_ 도/JX_ 조용히/MAG_ 집/NNG_ 으로/JKB_ 가/VV_ 는/ETM_ 시간/NNG_ ',\n",
       " ' [CLS] 바다/NNG_ 건너/VV_ 어/EC_ 해/VV_ 지/VX_ 는/ETM_ 풍경/NNG_ 은/JX_ 그야말로/MAG_ [UNK] 다/EC_ ',\n",
       " ' [CLS] [UNK] [UNK] 에/JKB_ [UNK] 이/JKS_ 하나/NR_ 둘/NR_ 켜/VV_ 지/VX_ ㄹ/ETM_ [UNK] ',\n",
       " ' [CLS] [UNK] 게/EC_ [UNK] 은/ETM_ [UNK] 같/VA_ 은/ETM_ 태양/NNG_ 이/JKS_ ',\n",
       " ' [CLS] [UNK] 과/JKB_ 함께/MAG_ [UNK] ㄴ/ETM_ 산/NNG_ 으로/JKB_ 지/VV_ 는/ETM_ 풍경/NNG_ 은/JX_ ',\n",
       " ' [CLS] 보/VV_ 지/EC_ 않/VX_ 고/EC_ 는/JX_ 그/MM_ [UNK] ㅁ/ETN_ 을/JKO_ 모르/VV_ ㄴ다/EC_ ',\n",
       " '']"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = ' '.join(a).split('[SEP]')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9GIh6eSv4KyW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
