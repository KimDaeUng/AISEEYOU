{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model('wiki.ko.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "abc =[]\n",
    "if len(abc) == 0:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_noun_token.pkl', 'rb') as f:\n",
    "    noun_poem = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_restaurant.json', 'rb') as f:\n",
    "     json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_poem[72871]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(noun_poem)):\n",
    "    if len(noun_poem[i]) == 0:\n",
    "        noun_poem[i] = ['ㄱ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ㄱ']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_poem[72871]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14585072, -0.05697468,  0.01723144, -0.6104529 , -0.20027426,\n",
       "       -0.31516284,  0.21025552,  0.3652413 ,  0.2054401 , -0.27428314,\n",
       "        0.43912563, -0.17086561, -0.12134538, -0.01043081,  0.04719607,\n",
       "        0.7188509 , -0.1977248 , -0.18490238,  0.32652703, -0.7861228 ,\n",
       "        0.47446176,  0.04646264,  0.11111563, -0.14190601,  0.14996429,\n",
       "       -0.02629222,  0.12235566, -0.2457167 ,  0.77583176,  0.43908212,\n",
       "        0.3446259 ,  0.27290827,  0.8985327 , -0.49472713, -0.49604836,\n",
       "        0.27263352,  0.00150859,  0.70662814,  0.05986288,  0.05645159,\n",
       "        0.41183358,  0.00628037, -0.01708329, -0.290755  ,  0.15470175,\n",
       "       -0.79381645,  0.06265634, -0.12048581,  0.29121944, -0.31810993,\n",
       "        0.01851534,  0.15312102, -0.32791287,  0.05859427,  0.273266  ,\n",
       "        0.13241272, -0.21695583,  0.39952713,  0.18349452, -0.1979415 ,\n",
       "        0.39211693,  0.6216357 ,  0.29389158, -0.73234874,  0.10746191,\n",
       "       -0.15379761, -0.01099653,  0.06230582, -0.06029487,  0.19326864,\n",
       "        0.13317873, -0.17184295, -0.08369476, -0.21804808, -0.03916709,\n",
       "        0.15217315,  0.22933878,  0.02154096,  0.17876387,  0.22035988,\n",
       "        0.18344249,  0.2705266 ,  0.19291618,  0.04145433, -0.5773451 ,\n",
       "        0.05022541,  0.36422932, -0.36309603,  0.17681578, -0.11270874,\n",
       "       -0.18354268, -0.11041257,  0.02818414, -0.02463591,  0.5870204 ,\n",
       "        0.137608  , -0.08452143,  0.35192123, -0.5223016 ,  0.2818984 ,\n",
       "        0.20290005,  0.12813158, -0.32772055, -0.31137165,  0.5016959 ,\n",
       "        0.29540864, -0.24231525,  0.46160507, -0.43453878, -0.19684333,\n",
       "        0.48351595,  0.57388675, -0.3142283 , -0.15705933, -0.37931082,\n",
       "       -0.01002541, -0.16682352,  0.34911123, -0.3646199 ,  0.13687031,\n",
       "        0.96809864, -0.55545837,  0.20983036, -0.08079689, -0.48028374,\n",
       "       -0.03597967,  0.6929151 ,  0.32144833,  0.10308806,  0.9510155 ,\n",
       "        0.03933089,  0.02297402, -0.25137085, -0.11179236,  0.20633897,\n",
       "        0.28157315, -0.02667863,  0.70541936, -0.0688453 , -0.1654673 ,\n",
       "        0.07702443,  0.63466275, -0.2721074 , -0.14585483,  0.0447353 ,\n",
       "       -0.18155618, -0.10444623, -0.17565116, -1.3065397 ,  0.17345311,\n",
       "       -0.489417  , -0.18443717,  0.18038292,  0.52806973,  0.18220536,\n",
       "        0.54286206,  0.0077083 ,  0.32628098,  0.43564984,  0.43423536,\n",
       "        0.2149306 ,  0.49359396, -0.00166196,  0.3467103 ,  0.25427145,\n",
       "        0.74450904,  0.21344338, -0.41936535, -0.19515593,  0.08301429,\n",
       "        0.15227552,  0.24516614,  0.22929028, -0.67322445, -0.24169959,\n",
       "        0.3357733 , -0.0852043 , -0.7419702 ,  0.84492654, -0.34547448,\n",
       "        0.16581427,  0.05215712, -0.60935956, -0.25943625,  0.02029718,\n",
       "       -0.27024403,  0.22239538,  0.197083  ,  0.11496154, -0.06784948,\n",
       "        0.524062  ,  0.18969396,  0.26805073,  0.71312696, -0.36272043,\n",
       "        0.21756393, -0.04092462, -0.51482123,  0.03628739, -0.4723739 ,\n",
       "        0.5698698 , -0.5486158 , -0.6541706 , -0.26936713, -0.5158217 ,\n",
       "       -0.02336614, -0.03395718, -0.15335461, -0.10474566,  0.3668475 ,\n",
       "        0.3035544 , -0.27350727, -0.22083387,  0.20082715, -0.5407674 ,\n",
       "       -0.39049733,  0.03173798,  0.13551843,  0.42143756,  0.59433824,\n",
       "        0.37461793,  0.29987738,  0.06488286,  0.4319002 , -0.17438006,\n",
       "       -0.07011376, -0.27494517, -0.10436603,  0.14701897, -0.08257583,\n",
       "        0.32001618,  0.1578814 , -0.33890468, -0.0427063 , -0.17928565,\n",
       "        0.22228745, -0.14033593, -0.3483375 , -0.22830476, -0.46608067,\n",
       "       -0.09930871, -0.271092  , -0.88675594,  0.38005146,  0.14740248,\n",
       "        0.13486032, -0.28201282,  0.12210584, -0.01031883, -0.2502273 ,\n",
       "       -0.48555815, -0.07232711,  0.30251566, -0.48463854,  0.02603885,\n",
       "        0.5197328 ,  0.14526485,  0.2853234 ,  0.9571127 ,  0.14035554,\n",
       "       -0.34484538,  0.09503601,  0.9123396 , -0.29247293,  0.3092251 ,\n",
       "       -0.03508735, -0.49910033,  0.5379982 ,  0.24606673, -0.3787276 ,\n",
       "       -0.13248187,  0.5334488 , -0.42301416, -0.05150424,  0.01522272,\n",
       "        0.37423787, -0.3277893 , -0.5398696 , -0.48411274,  0.05934013,\n",
       "        0.0240132 , -0.3096712 ,  0.08772034,  0.5931552 ,  0.4524775 ,\n",
       "        0.20204702, -0.26139793, -0.45434898, -0.04821622, -0.32655668,\n",
       "       -0.23939429,  0.09783258,  0.30897248, -0.09610922,  0.53141445,\n",
       "        0.031973  ,  0.06521315, -0.10168508,  0.16594587, -0.61725396],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_word_vector(noun_poem[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74554"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 74554/74554 [01:11<00:00, 1037.90it/s]\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "for i in tqdm(range(len(noun_poem))):\n",
    "    sen = []\n",
    "    total.append(sen)\n",
    "    for j in range(len(noun_poem[i])):\n",
    "        if noun_poem[i][j] != word:\n",
    "            sen.append(model.get_word_vector(noun_poem[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_total = np.array([np.array(i) for i in total ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_total_samplesum = [ np.sum(i, axis=0) for i in new_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_total_samplesum = np.array(new_total_samplesum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_poem = new_total_samplesum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "word =['ㅂ','ㅈ','ㄷ','ㄱ','ㅅ','ㅁ','ㄴ','ㅇ','ㄹ','ㅎ','ㅋ','ㅌ','ㅊ','ㅍ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1107.89it/s]\n"
     ]
    }
   ],
   "source": [
    "tot = []\n",
    "for i in tqdm(range(len(json_data))):\n",
    "    sen = []\n",
    "    tot.append(sen)\n",
    "    for j in range(len(json_data[i]['keyword'])):\n",
    "        #if json_data[i]['keyword'][j] != word:\n",
    "            sen.append(model.get_word_vector(json_data[i]['keyword'][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tot = np.array([np.array(i) for i in tot ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tot_samplesum = [ np.sum(i, axis=0) for i in new_tot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tot_samplesum = np.array(new_tot_samplesum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_keyword = new_tot_samplesum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_poem[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_keyword[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosin Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 74554/74554 [00:00<00:00, 98762.75it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in tqdm(range(len(vector_poem))):\n",
    "    score = cosine_similarity(vector_keyword[1], vector_poem[i])\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74554"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9216004\n"
     ]
    }
   ],
   "source": [
    "print(max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16937"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.index(max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['레스토랑',\n",
       " '병',\n",
       " '나무',\n",
       " '테이블',\n",
       " '차',\n",
       " '의식',\n",
       " '결혼',\n",
       " '정물',\n",
       " '가구',\n",
       " '빵',\n",
       " '커피',\n",
       " '아침',\n",
       " '컵',\n",
       " 'ᄀ',\n",
       " '양',\n",
       " 'ᄃ',\n",
       " '포도주',\n",
       " '컨테이너',\n",
       " '칼',\n",
       " '식사',\n",
       " '한잔',\n",
       " '꽃',\n",
       " '과일',\n",
       " '식품',\n",
       " '유리']"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[1]['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_poem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['머릿속 생각을 안치고', '일상의 여유까지 삶는', '머그잔 대야에다 커피를 떠 세수한다', '머그잔 세숫대야에', '더운 아메리카노를 받아', '각설탕 스크럽 비누를 녹여', '피곤한 얼굴을 씻는다', '커피 향기를 몸으로 끌어안고', '면도날처럼 예리한 향기의 칼날로', '주말의 턱수염도 깎는다', '돌돌 말아서 개어놓은', '몽블랑데니쉬 세면 타월로', '한결 촉촉해진 위장의 얼굴까지 닦는다', '내일 새벽에는', '찬 우유에 식빵 행주 한 장 빨아서', '월요일 아침 밥상을 닦아야겠다', '커피와 먹으면 세상 맛있는 빵이 너무 많다', '산다는 것은 커피와 빵을 사랑하는 일 같다']\""
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['contents_re'][16937]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_index(vector_keyword, vector_poem):\n",
    "    scores = []\n",
    "    for i in range(len(vector_poem)):\n",
    "        score = cosine_similarity(vector_keyword, vector_poem[i])\n",
    "        scores.append(score)\n",
    "    index = scores.index(max(scores))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16937"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_index(vector_keyword[1], vector_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(len(vector_keyword)):\n",
    "    index = return_index(vector_keyword[i], vector_poem)\n",
    "    index_list.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(index_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "for i in index_list:\n",
    "    text_list.append(data.contents_re[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['년은 어디로 가나', '빵이 우리의 주식이 되면', '밥상 위의 쌀밥은 어디로 가나', '통조림 빈깡통만 나딍구는 거리에서', '마르크스와 레닌의 마시다 버린 술', '빈병을 발길질 한다', '혀끗의 간교한 이간질에 입맛을 잃은', '김치와 쌀밥은 어디로 가나', '빵의 단조로운 멜로디에', '커피 또는 밀크로 목을 축이며', '나를 버린 나의 과거라도', '버터를 발라 씹어야 하는', '우리의 손시린 년은 어디로 가나', '내 가슴에 아직도 살아 숨쉬는', '계절을 타지 않는', '여인들의 풀린 속옷', '단춧구멍에 매달려', '년은 개처럼 헐떡이며 끌려가고']\",\n",
       " \"['머릿속 생각을 안치고', '일상의 여유까지 삶는', '머그잔 대야에다 커피를 떠 세수한다', '머그잔 세숫대야에', '더운 아메리카노를 받아', '각설탕 스크럽 비누를 녹여', '피곤한 얼굴을 씻는다', '커피 향기를 몸으로 끌어안고', '면도날처럼 예리한 향기의 칼날로', '주말의 턱수염도 깎는다', '돌돌 말아서 개어놓은', '몽블랑데니쉬 세면 타월로', '한결 촉촉해진 위장의 얼굴까지 닦는다', '내일 새벽에는', '찬 우유에 식빵 행주 한 장 빨아서', '월요일 아침 밥상을 닦아야겠다', '커피와 먹으면 세상 맛있는 빵이 너무 많다', '산다는 것은 커피와 빵을 사랑하는 일 같다']\",\n",
       " \"['년은 어디로 가나', '빵이 우리의 주식이 되면', '밥상 위의 쌀밥은 어디로 가나', '통조림 빈깡통만 나딍구는 거리에서', '마르크스와 레닌의 마시다 버린 술', '빈병을 발길질 한다', '혀끗의 간교한 이간질에 입맛을 잃은', '김치와 쌀밥은 어디로 가나', '빵의 단조로운 멜로디에', '커피 또는 밀크로 목을 축이며', '나를 버린 나의 과거라도', '버터를 발라 씹어야 하는', '우리의 손시린 년은 어디로 가나', '내 가슴에 아직도 살아 숨쉬는', '계절을 타지 않는', '여인들의 풀린 속옷', '단춧구멍에 매달려', '년은 개처럼 헐떡이며 끌려가고']\",\n",
       " \"['손수건 반죽을', '다리미 오븐에 넣어 구우면', '따뜻한 식빵이 완성된다', '나는 날마다', '손수건으로 반듯한 식빵을 만든다', '세상에서 가장 비싼', '너의 유기농 눈물 잼을 바르고 싶어서']\",\n",
       " \"['년은 어디로 가나', '빵이 우리의 주식이 되면', '밥상 위의 쌀밥은 어디로 가나', '통조림 빈깡통만 나딍구는 거리에서', '마르크스와 레닌의 마시다 버린 술', '빈병을 발길질 한다', '혀끗의 간교한 이간질에 입맛을 잃은', '김치와 쌀밥은 어디로 가나', '빵의 단조로운 멜로디에', '커피 또는 밀크로 목을 축이며', '나를 버린 나의 과거라도', '버터를 발라 씹어야 하는', '우리의 손시린 년은 어디로 가나', '내 가슴에 아직도 살아 숨쉬는', '계절을 타지 않는', '여인들의 풀린 속옷', '단춧구멍에 매달려', '년은 개처럼 헐떡이며 끌려가고']\",\n",
       " \"['머릿속 생각을 안치고', '일상의 여유까지 삶는', '머그잔 대야에다 커피를 떠 세수한다', '머그잔 세숫대야에', '더운 아메리카노를 받아', '각설탕 스크럽 비누를 녹여', '피곤한 얼굴을 씻는다', '커피 향기를 몸으로 끌어안고', '면도날처럼 예리한 향기의 칼날로', '주말의 턱수염도 깎는다', '돌돌 말아서 개어놓은', '몽블랑데니쉬 세면 타월로', '한결 촉촉해진 위장의 얼굴까지 닦는다', '내일 새벽에는', '찬 우유에 식빵 행주 한 장 빨아서', '월요일 아침 밥상을 닦아야겠다', '커피와 먹으면 세상 맛있는 빵이 너무 많다', '산다는 것은 커피와 빵을 사랑하는 일 같다']\",\n",
       " \"['년은 어디로 가나', '빵이 우리의 주식이 되면', '밥상 위의 쌀밥은 어디로 가나', '통조림 빈깡통만 나딍구는 거리에서', '마르크스와 레닌의 마시다 버린 술', '빈병을 발길질 한다', '혀끗의 간교한 이간질에 입맛을 잃은', '김치와 쌀밥은 어디로 가나', '빵의 단조로운 멜로디에', '커피 또는 밀크로 목을 축이며', '나를 버린 나의 과거라도', '버터를 발라 씹어야 하는', '우리의 손시린 년은 어디로 가나', '내 가슴에 아직도 살아 숨쉬는', '계절을 타지 않는', '여인들의 풀린 속옷', '단춧구멍에 매달려', '년은 개처럼 헐떡이며 끌려가고']\",\n",
       " \"['손병흥', '아주 저렴한 가격으로도 세계음식 맛볼 수 있는', '저녁 시부터 시까지만 운영하는 간이 좌판대', '부산에서도 유일한 명물 부평동 깡통야시장 거리', '조그만 판매대 공간에서도 소박한 꿈들을 키워나가는', '경쟁이 일상 되어버린 활기 잃어가던 전통시장골목에', '서로 상생의 길 모색할 수 있었던 부산여행 추천 지역', '솜사탕 아이스크림 닭 꼬치에 비빔당면 볶음국수 튀김', '명품어묵으로 밤나들이를 즐겨보는 부산 먹자골목투어', '각종 시장 표 야식 먹을거리가 풍부하기에 가볼만한 곳']\",\n",
       " \"['틸라묵 치즈공장에서', '틸라묵 치즈공장', '간만에 방문하여', '유제품 제조공정', '한 눈에 바라보다', '각종 제품을', '혀끝으로 맛보네', '젖소들 짜낸 우유', '이곳에 집하되어', '첨단의 신기술로', '가공된 제품들이', '이목을 끌어', '그 명성이 높구나', '오레곤주 태평양 연안에 있는  치즈공장은', '년에 창사되어 지금까지 꾸준히 성장발전하고', '있으며 틸라묵 치즈는 세계적으로 유명하다']\",\n",
       " \"['손병흥', '전 세계에서도 오로지 한국에서만 가능한', '한꺼번에 다양한 반찬 나오는 풍성한 식탁', '인심 좋고 정이 넘쳐 풍족한 우리네의 삶', '버리는 것 없이 두루 살필 수 있는 포용력', '음식 종류와 맛이나 영양만으로는 설명을 못할', '지역별 각기 다른 식자재로 만들어지는 위대함', '밥과 반찬 나물 장 채소 고기와 김치까지 곁들여', '비로소 입안에서 섞이며 완성되는 우리의 상차림', '신토불이 재료와 다양한 조리법으로도 각광을 받는', '우리민족의 지혜로 세계인이 인정하는 음식중 하나', '숙성된 잘 익은 간장이나 된장 발효액으로 맛을 내', '과학적으로 받아들인 자연원리 비교불가의 발효기술']\"]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
